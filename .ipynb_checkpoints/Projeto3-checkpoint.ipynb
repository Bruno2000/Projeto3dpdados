{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Ciência dos Dados - PROJETO 3 - INSPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Bruno Morales Balkins\n",
    "\n",
    "#### Daniel do Carmo Granja de Castro\n",
    "\n",
    "#### Omar Dibo Calixto Afrange Neto\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qual a chance de um estudante entrar em uma faculdade baseado em diversos parametros relacionados a notas em exames e qualidade da faculdade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## A. INTRODUÇÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa base de dados contem informações sobre alguns candidatos de universidades variadas. As variáveis incluem notas em alguns testes, experiência com pesquisa, carta de recomendação e outros quesitos necessários, além disso ela traz a probabilidade dele ser aceito na universidade desejada. O intuito deste projeto é prever a probabilidade do aluno conseguir passar na universidade a partir de modelos de regressão e comparar com o valor real de probabilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B. MINERANDO DADOS e CARACTERÍSTICAS DO DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Detalhe aqui as características da base de dados além da análise descritiva.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "documents/github/projeto3dpdados/\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(\"documents/github/projeto3dpdados/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASE DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>330</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>321</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>308</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>302</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>323</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>325</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>327</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>328</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>307</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>311</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>314</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>317</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>312</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>325</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>328</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>334</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>336</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>340</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>322</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>298</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>295</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>310</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>371</td>\n",
       "      <td>310</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>372</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>373</td>\n",
       "      <td>336</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>374</td>\n",
       "      <td>321</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>375</td>\n",
       "      <td>315</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>376</td>\n",
       "      <td>304</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>377</td>\n",
       "      <td>297</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>378</td>\n",
       "      <td>290</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>379</td>\n",
       "      <td>303</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>380</td>\n",
       "      <td>311</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>381</td>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>382</td>\n",
       "      <td>319</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>383</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>384</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>385</td>\n",
       "      <td>340</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>386</td>\n",
       "      <td>335</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>387</td>\n",
       "      <td>302</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>388</td>\n",
       "      <td>307</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>389</td>\n",
       "      <td>296</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>390</td>\n",
       "      <td>320</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>391</td>\n",
       "      <td>314</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>392</td>\n",
       "      <td>318</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>393</td>\n",
       "      <td>326</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>394</td>\n",
       "      <td>317</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>395</td>\n",
       "      <td>329</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "5             6        330          115                  5  4.5   3.0  9.34   \n",
       "6             7        321          109                  3  3.0   4.0  8.20   \n",
       "7             8        308          101                  2  3.0   4.0  7.90   \n",
       "8             9        302          102                  1  2.0   1.5  8.00   \n",
       "9            10        323          108                  3  3.5   3.0  8.60   \n",
       "10           11        325          106                  3  3.5   4.0  8.40   \n",
       "11           12        327          111                  4  4.0   4.5  9.00   \n",
       "12           13        328          112                  4  4.0   4.5  9.10   \n",
       "13           14        307          109                  3  4.0   3.0  8.00   \n",
       "14           15        311          104                  3  3.5   2.0  8.20   \n",
       "15           16        314          105                  3  3.5   2.5  8.30   \n",
       "16           17        317          107                  3  4.0   3.0  8.70   \n",
       "17           18        319          106                  3  4.0   3.0  8.00   \n",
       "18           19        318          110                  3  4.0   3.0  8.80   \n",
       "19           20        303          102                  3  3.5   3.0  8.50   \n",
       "20           21        312          107                  3  3.0   2.0  7.90   \n",
       "21           22        325          114                  4  3.0   2.0  8.40   \n",
       "22           23        328          116                  5  5.0   5.0  9.50   \n",
       "23           24        334          119                  5  5.0   4.5  9.70   \n",
       "24           25        336          119                  5  4.0   3.5  9.80   \n",
       "25           26        340          120                  5  4.5   4.5  9.60   \n",
       "26           27        322          109                  5  4.5   3.5  8.80   \n",
       "27           28        298           98                  2  1.5   2.5  7.50   \n",
       "28           29        295           93                  1  2.0   2.0  7.20   \n",
       "29           30        310           99                  2  1.5   2.0  7.30   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "370         371        310          103                  2  2.5   2.5  8.24   \n",
       "371         372        324          110                  3  3.5   3.0  9.22   \n",
       "372         373        336          119                  4  4.5   4.0  9.62   \n",
       "373         374        321          109                  3  3.0   3.0  8.54   \n",
       "374         375        315          105                  2  2.0   2.5  7.65   \n",
       "375         376        304          101                  2  2.0   2.5  7.66   \n",
       "376         377        297           96                  2  2.5   2.0  7.43   \n",
       "377         378        290          100                  1  1.5   2.0  7.56   \n",
       "378         379        303           98                  1  2.0   2.5  7.65   \n",
       "379         380        311           99                  1  2.5   3.0  8.43   \n",
       "380         381        322          104                  3  3.5   4.0  8.84   \n",
       "381         382        319          105                  3  3.0   3.5  8.67   \n",
       "382         383        324          110                  4  4.5   4.0  9.15   \n",
       "383         384        300          100                  3  3.0   3.5  8.26   \n",
       "384         385        340          113                  4  5.0   5.0  9.74   \n",
       "385         386        335          117                  5  5.0   5.0  9.82   \n",
       "386         387        302          101                  2  2.5   3.5  7.96   \n",
       "387         388        307          105                  2  2.0   3.5  8.10   \n",
       "388         389        296           97                  2  1.5   2.0  7.80   \n",
       "389         390        320          108                  3  3.5   4.0  8.44   \n",
       "390         391        314          102                  2  2.0   2.5  8.24   \n",
       "391         392        318          106                  3  2.0   3.0  8.65   \n",
       "392         393        326          112                  4  4.0   3.5  9.12   \n",
       "393         394        317          104                  2  3.0   3.0  8.76   \n",
       "394         395        329          111                  4  4.5   4.0  9.23   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "5           1              0.90  \n",
       "6           1              0.75  \n",
       "7           0              0.68  \n",
       "8           0              0.50  \n",
       "9           0              0.45  \n",
       "10          1              0.52  \n",
       "11          1              0.84  \n",
       "12          1              0.78  \n",
       "13          1              0.62  \n",
       "14          1              0.61  \n",
       "15          0              0.54  \n",
       "16          0              0.66  \n",
       "17          1              0.65  \n",
       "18          0              0.63  \n",
       "19          0              0.62  \n",
       "20          1              0.64  \n",
       "21          0              0.70  \n",
       "22          1              0.94  \n",
       "23          1              0.95  \n",
       "24          1              0.97  \n",
       "25          1              0.94  \n",
       "26          0              0.76  \n",
       "27          1              0.44  \n",
       "28          0              0.46  \n",
       "29          0              0.54  \n",
       "..        ...               ...  \n",
       "370         0              0.72  \n",
       "371         1              0.89  \n",
       "372         1              0.95  \n",
       "373         1              0.79  \n",
       "374         0              0.39  \n",
       "375         0              0.38  \n",
       "376         0              0.34  \n",
       "377         0              0.47  \n",
       "378         0              0.56  \n",
       "379         1              0.71  \n",
       "380         1              0.78  \n",
       "381         1              0.73  \n",
       "382         1              0.82  \n",
       "383         0              0.62  \n",
       "384         1              0.96  \n",
       "385         1              0.96  \n",
       "386         0              0.46  \n",
       "387         0              0.53  \n",
       "388         0              0.49  \n",
       "389         1              0.76  \n",
       "390         0              0.64  \n",
       "391         0              0.71  \n",
       "392         1              0.84  \n",
       "393         0              0.77  \n",
       "394         1              0.89  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = pd.read_csv('Admission_Predict.csv')\n",
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serial No.: Número de série do aluno\n",
    "\n",
    "GRE Scores: Nota do aluno no teste GRE\n",
    "\n",
    "TOEFL Scores: Nota do aluno no teste TOEFL\n",
    "\n",
    "University Rating: Classificação do nível de ensino da universidade desejada\n",
    "\n",
    "Statment of purpose (SOP): Qualidade do texto sobre o objeto de pesquisa do aluno\n",
    "\n",
    "Letter of recomendation (LOR): Qualidade da carta de recomendação do aluno\n",
    "\n",
    "Undergraduate Grade Point Average (CGPA): Média acadêmica do aluno\n",
    "\n",
    "Research: Experiência com pesquisa. 1- Sim, 2- Não\n",
    "\n",
    "Change of Admission: Probabilidade de admissão do aluno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dados = dados.drop(\"Serial No.\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANÁLISE DESCRITIVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variáveis Quantitativas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "plot = dados[\"GRE Score\"].plot.hist(bins=50,title='GRE Score', alpha=0.9)\n",
    "plt.ylabel('Frequência Absoluta')\n",
    "plt.xlabel('Nota do aluno')\n",
    "\n",
    "plt.subplot(132)\n",
    "plot = dados[\"TOEFL Score\"].plot.hist(bins=25,title='TOEFL Score', alpha=0.9)\n",
    "plt.ylabel('Frequência Absoluta')\n",
    "plt.xlabel('Nota do aluno')\n",
    "\n",
    "plt.subplot(133)\n",
    "plot = dados[\"CGPA\"].plot.hist(bins=50,title='CGPA', alpha=0.9)\n",
    "plt.ylabel('Frequência Absoluta')\n",
    "plt.xlabel('Média do aluno')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.subplot(121)\n",
    "adQuantitativa2 = dados[\"LOR \"].value_counts()\n",
    "plot = adQuantitativa2.plot(kind='bar', legend=False,title=\"LOR\");\n",
    "plt.ylabel('Frequência Absoluta')\n",
    "plt.xlabel('Nota do aluno')\n",
    "\n",
    "plt.subplot(122)\n",
    "adQuantitativa3 = dados[\"SOP\"].value_counts()\n",
    "plot = adQuantitativa3.plot(kind='bar', legend=False,title=\"SOP\");\n",
    "plt.ylabel('Frequência Absoluta')\n",
    "plt.xlabel('Nota do aluno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variável Qualitativa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-db87038f8fc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0madQualitativa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Research'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0madQualitativa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pie'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautopct\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%0.2f\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dados' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.subplot(121)\n",
    "adQualitativa = dados['Research'].value_counts()\n",
    "adQualitativa.plot(kind='pie', autopct=\"%0.2f\",legend=False);\n",
    "\n",
    "plt.subplot(122)\n",
    "adQuantitativa = dados['University Rating'].value_counts()\n",
    "adQuantitativa.plot(kind='pie', autopct=\"%0.2f\",legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a análise univariada vamos estudar como elas se correlacionam. Utilzaremos uma matriz de cores para entender a influência de cada uma delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f77bb053c69f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorrel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcorrel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'GRE Score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TOEFL Score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CGPA'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SOP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'LOR '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Research'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Chance of Admit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dados' is not defined"
     ]
    }
   ],
   "source": [
    "correl = dados.iloc[:,:7].corr()\n",
    "correl\n",
    "names = ['GRE Score','TOEFL Score','CGPA','SOP','LOR ','Research','Chance of Admit']\n",
    "d = len(names)\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correl, interpolation='none', vmin=-1, vmax=1 ,alpha=0.8)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,d,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_yticklabels(names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## C. MODELOS DE PREDIÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9a0fe11bd0c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainingSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdados\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dados' is not defined"
     ]
    }
   ],
   "source": [
    "trainingSet, testSet = train_test_split(dados, test_size = 0.25)\n",
    "testSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "o MODELO DE PREDIÇÃO PELA MÉDIA (Sem uso de variável explicativa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainingSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-371cb3e137b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0madmissao\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainingSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Chance of Admit '\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madmissao\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0madmissao2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Chance of Admit '\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmu2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madmissao2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainingSet' is not defined"
     ]
    }
   ],
   "source": [
    "admissao = trainingSet['Chance of Admit ']\n",
    "mu = admissao.mean()\n",
    "\n",
    "admissao2 = testSet['Chance of Admit ']\n",
    "mu2 = admissao2.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7211, 0.7340999999999999)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, mu2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "o MODELO DOS K VIZINHOS MAIS PRÓXIMOS (K-Nearest Neighbors Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "o MODELO DE REGRESSÃO LINEAR (Multiple Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress(X,Y):\n",
    "    X_cp = sm.add_constant(X)\n",
    "    model = sm.OLS(Y,X_cp)\n",
    "    results = model.fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trainingSet[['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ','CGPA', 'Research','Chance of Admit ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ','CGPA', 'Research']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>Chance of Admit </td> <th>  R-squared:         </th> <td>   0.807</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.802</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   173.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 28 May 2019</td> <th>  Prob (F-statistic):</th> <td>3.25e-100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:34:51</td>     <th>  Log-Likelihood:    </th> <td>  403.68</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   300</td>      <th>  AIC:               </th> <td>  -791.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   292</td>      <th>  BIC:               </th> <td>  -761.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>   -1.2644</td> <td>    0.149</td> <td>   -8.506</td> <td> 0.000</td> <td>   -1.557</td> <td>   -0.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRE Score</th>         <td>    0.0020</td> <td>    0.001</td> <td>    2.882</td> <td> 0.004</td> <td>    0.001</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TOEFL Score</th>       <td>    0.0023</td> <td>    0.001</td> <td>    1.756</td> <td> 0.080</td> <td>   -0.000</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>University Rating</th> <td>    0.0066</td> <td>    0.005</td> <td>    1.223</td> <td> 0.222</td> <td>   -0.004</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SOP</th>               <td>   -0.0014</td> <td>    0.006</td> <td>   -0.220</td> <td> 0.826</td> <td>   -0.014</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LOR </th>              <td>    0.0218</td> <td>    0.006</td> <td>    3.385</td> <td> 0.001</td> <td>    0.009</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CGPA</th>              <td>    0.1159</td> <td>    0.014</td> <td>    8.114</td> <td> 0.000</td> <td>    0.088</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Research</th>          <td>    0.0270</td> <td>    0.009</td> <td>    2.916</td> <td> 0.004</td> <td>    0.009</td> <td>    0.045</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>74.184</td> <th>  Durbin-Watson:     </th> <td>   2.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 156.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.245</td> <th>  Prob(JB):          </th> <td>1.28e-34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.507</td> <th>  Cond. No.          </th> <td>1.35e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.35e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       Chance of Admit    R-squared:                       0.807\n",
       "Model:                            OLS   Adj. R-squared:                  0.802\n",
       "Method:                 Least Squares   F-statistic:                     173.9\n",
       "Date:                Tue, 28 May 2019   Prob (F-statistic):          3.25e-100\n",
       "Time:                        14:34:51   Log-Likelihood:                 403.68\n",
       "No. Observations:                 300   AIC:                            -791.4\n",
       "Df Residuals:                     292   BIC:                            -761.7\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "const                -1.2644      0.149     -8.506      0.000      -1.557      -0.972\n",
       "GRE Score             0.0020      0.001      2.882      0.004       0.001       0.003\n",
       "TOEFL Score           0.0023      0.001      1.756      0.080      -0.000       0.005\n",
       "University Rating     0.0066      0.005      1.223      0.222      -0.004       0.017\n",
       "SOP                  -0.0014      0.006     -0.220      0.826      -0.014       0.011\n",
       "LOR                   0.0218      0.006      3.385      0.001       0.009       0.035\n",
       "CGPA                  0.1159      0.014      8.114      0.000       0.088       0.144\n",
       "Research              0.0270      0.009      2.916      0.004       0.009       0.045\n",
       "==============================================================================\n",
       "Omnibus:                       74.184   Durbin-Watson:                   2.103\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              156.088\n",
       "Skew:                          -1.245   Prob(JB):                     1.28e-34\n",
       "Kurtosis:                       5.507   Cond. No.                     1.35e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.35e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = regress(X,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_previsao_treinamento = -1.4346 + trainingSet['GRE Score']*0.0026 + trainingSet['TOEFL Score']*0.0022 + trainingSet['University Rating']*0.0077 - trainingSet['SOP']*0.0003 + trainingSet['LOR ']*0.022 + trainingSet['CGPA']*0.1166 + trainingSet['Research']*0.027\n",
    "\n",
    "valor_previsao_teste = -1.4346 + testSet['GRE Score']*0.0026 + testSet['TOEFL Score']*0.0022 + testSet['University Rating']*0.0077 - testSet['SOP']*0.0003 + testSet['LOR ']*0.022 + testSet['CGPA']*0.1166 + testSet['Research']*0.027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160    0.578726\n",
       " 96     0.594300\n",
       " 225    0.558748\n",
       " 371    0.839902\n",
       " 63     0.718100\n",
       " 56     0.562740\n",
       " 206    0.602524\n",
       " 309    0.706710\n",
       " 240    0.525638\n",
       " 213    0.996348\n",
       " 108    0.948908\n",
       " 72     0.920070\n",
       " 114    0.705320\n",
       " 320    0.739800\n",
       " 301    0.734466\n",
       " 45     0.857660\n",
       " 104    0.829680\n",
       " 359    0.667304\n",
       " 316    0.537826\n",
       " 337    0.966402\n",
       " 343    0.624608\n",
       " 242    0.797266\n",
       " 110    0.688368\n",
       " 54     0.676600\n",
       " 157    0.630516\n",
       " 38     0.501100\n",
       " 146    0.681668\n",
       " 205    0.522840\n",
       " 46     0.930280\n",
       " 66     0.806332\n",
       "          ...   \n",
       " 112    0.681894\n",
       " 339    0.805406\n",
       " 235    0.885568\n",
       " 28     0.427620\n",
       " 192    0.847954\n",
       " 167    0.656382\n",
       " 260    0.858758\n",
       " 117    0.503236\n",
       " 174    0.834702\n",
       " 357    0.615124\n",
       " 150    0.928738\n",
       " 156    0.665344\n",
       " 55     0.610020\n",
       " 360    0.810924\n",
       " 4      0.646486\n",
       " 356    0.815032\n",
       " 228    0.748422\n",
       " 109    0.714824\n",
       " 119    0.816744\n",
       " 18     0.748180\n",
       " 208    0.623556\n",
       " 288    0.801632\n",
       " 26     0.782630\n",
       " 103    0.708052\n",
       " 133    0.811648\n",
       " 159    0.529990\n",
       " 164    0.860016\n",
       " 209    0.660642\n",
       " 84     0.967420\n",
       " 24     0.984780\n",
       " Length: 300, dtype: float64, 214    0.948222\n",
       " 261    0.658744\n",
       " 107    0.960386\n",
       " 165    0.815652\n",
       " 177    0.789914\n",
       " 111    0.796488\n",
       " 222    0.798764\n",
       " 162    0.711300\n",
       " 363    0.643026\n",
       " 128    0.835510\n",
       " 369    0.599998\n",
       " 312    0.814250\n",
       " 121    0.964118\n",
       " 158    0.613124\n",
       " 323    0.606388\n",
       " 294    0.664962\n",
       " 293    0.645638\n",
       " 255    0.710142\n",
       " 207    0.667982\n",
       " 325    0.870974\n",
       " 120    0.982496\n",
       " 393    0.720316\n",
       " 305    0.791930\n",
       " 171    0.912062\n",
       " 57     0.502360\n",
       " 42     0.691350\n",
       " 116    0.671192\n",
       " 47     0.964770\n",
       " 14     0.651970\n",
       " 290    0.567240\n",
       "          ...   \n",
       " 144    0.820036\n",
       " 149    0.677666\n",
       " 172    0.875758\n",
       " 73     0.817914\n",
       " 233    0.608412\n",
       " 52     0.744400\n",
       " 191    0.868568\n",
       " 77     0.582752\n",
       " 143    1.014522\n",
       " 353    0.599472\n",
       " 97     0.871636\n",
       " 295    0.678362\n",
       " 321    0.755004\n",
       " 372    0.966942\n",
       " 248    0.821092\n",
       " 306    0.834160\n",
       " 394    0.885668\n",
       " 327    0.529726\n",
       " 212    1.000856\n",
       " 37     0.537280\n",
       " 25     0.995910\n",
       " 258    0.825116\n",
       " 1      0.833042\n",
       " 105    0.800648\n",
       " 193    0.983948\n",
       " 179    0.640482\n",
       " 220    0.735950\n",
       " 303    0.763580\n",
       " 252    0.726614\n",
       " 283    0.797290\n",
       " Length: 100, dtype: float64)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valor_previsao_treinamento, valor_previsao_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "o MODELO DE ÁRVORES DE REGRESSÃO (Decision Tree Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ca5598d440e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Research\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Chance of Admit \"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mregressor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'green'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dados' is not defined"
     ]
    }
   ],
   "source": [
    "X = dados[[\"Research\"]]\n",
    "Y = dados[\"Chance of Admit \"]\n",
    "regressor = DecisionTreeRegressor(random_state = 1)\n",
    "regressor.fit(X, Y)\n",
    "plt.scatter(X, Y, color = 'green')\n",
    "plt.plot(X, regressor.predict(X), color = 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## D. PROCESSO E ESTATÍSTICAS DE VALIDAÇÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Esse item depende dos resultados das modelagens anteriores! Organize-os aqui de forma clara!]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = (admissao - mu)**2\n",
    "   \n",
    "adm2 = (admissao2 - mu)**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = adm.mean()\n",
    "y = adm2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmstreino = x**0.5\n",
    "rmsteste = y**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.143247303639545, 0.1401042112143671)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmstreino, rmsteste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESSAO LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "admregressao = (admissao - valor_previsao_treinamento)**2\n",
    "\n",
    "admregressao2 = (admissao2-valor_previsao_teste)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = admregressao.mean()\n",
    "y2 = admregressao2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmstreino2 = x2**0.5\n",
    "rmsteste2 = y2**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06397825056657926"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmstreino2, rmsteste2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## E. CONCLUSÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## F. REFERÊNCIAS BIBLIOGRÁFICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
